---
lang: pt
title: "Introdu√ß√£o √† Ci√™ncia de Dados"
subtitle: "Mestrado Profissional em Administra√ß√£o"
author: "Prof. Washington Santos da Silva"
institute: "IFMG - Campus Formiga"
date: 2025-07-10
date-format: long
format: 
  revealjs:
    theme: [default, custom.scss]
    embed-resources: true
    controls: true
    footer: "Prof. Washington Silva - Introdu√ß√£o √† Ci√™ncia de Dados"
    scrollable: true
    slide-number: true
    progress: true
    incremental: false
    transition: concave
    code-link: true
    overview: true
    fig-cap-location: bottom
    logo: img/logo_teste.jpeg
    css: logo.css
execute: 
  echo: true
  message: false
  warning: false
bibliography: referencias.bibtex
csl: associacao-brasileira-de-normas-tecnicas-ipea.csl
editor: source
---



```{r}
#| label: setup
#| echo: false

# Cofigura√ß√µes para exibic√£o de n√∫meros
options(
  digits = 5, # n√∫mero de casas decimais
  scipen = 999 # desativa nota√ß√£o cient√≠fica
)

# carrega pacotes
library(tidyverse)
library(ggpubr)
```



## Di√°rio de Bordo {.smaller}

::: {.callout-note icon=false}
## O que vimos at√© aqui?

- Aula 1 ‚úÖ

    - Apresenta√ß√£o da Disciplina ‚úÖ
    - Introdu√ß√£o e Contextualiza√ß√£o ‚úÖ
    - O que √© Ci√™ncia de Dados? ‚úÖ
    - Pesquisa Reproduz√≠vel e Ci√™ncia de Dados ‚úÖ
    - Pap√©is Profissionais ‚úÖ
    - Aplica√ß√µes ‚úÖ   
    - Habilidades Interpessoais e Anal√≠ticas ‚úÖ 
    - Apresenta√ß√£o da Disciplina ‚úÖ
    - Configura√ß√µes: Git/GitHub ‚úÖ 

- Aula 2 ‚úÖ  

    - Metodologia CRISP-DM ‚úÖ 
    - Tipos de An√°lise de Dados ‚úÖ  
    - Introdu√ß√£o ao RStudio e cria√ß√£o do **seu** Projeto da Disciplina ‚úÖ 
    - Introdu√ß√£o ao Sistema de Publica√ß√£o Quarto ‚úÖ 
    - Introdu√ß√£o ao Git e GitHub: controle de vers√£o e cria√ß√£o do **seu** 
      reposit√≥rio no GitHub ‚úÖ 

- Aula 3 ‚úÖ 

    - Breve Revis√£o sobre o RStudio ‚úÖ  
    - Sistema de Publica√ß√£o Quarto: (Cont.) ‚úÖ 
    - Introdu√ß√£o ao Git e GitHub:  (Cont.) ‚úÖ 
    - Sess√£o Pr√°tica: Fluxo de trabalho integrando RStudio/Quarto/R/Git/GitHub ‚úÖ 

- Aula 4 ‚úÖ 

    - Conceitos de Vari√°veis e Observa√ß√µes em Estat√≠stica ‚úÖ 
    - Conceito de Dados Organizados (*Tidy Data*) ‚úÖ 
    - Tipos at√¥micos e classes principais de dados da linguagem R ‚úÖ 
    - Tipos de Dados Tradicionais em Finan√ßas: ‚úÖ 
    
        - Dados em Sec√ß√£o-Cruzada (ou Transversal) (*Cross-Section Data*) ‚úÖ 
        - Dados em Sec√ß√µes-Cruzadas Combinadas (*Pooled Cross-Section Data*) ‚úÖ 
        - Dados em S√©ries Temporais (*Time Series Data*) ‚úÖ 
        - Dados em Painel (ou Longitudinais) (*Panel Data*) ‚úÖ 
        
    - Importa√ß√£o e Prepara√ß√£o de Dados T√≠picos de Finan√ßas com exemplos pr√°ticos ‚úÖ

- Aula 5 ‚úÖ

    - Metodologia CRISP-DM: Fases 2 e 3 ‚úÖ
    - Revis√£o sobre Dados Organizados (*Tidy Data*) ‚úÖ
    - Introdu√ß√£o ao Pacote tidyr: fun√ß√£o pivot_longer() ‚úÖ
    - Introdu√ß√£o ao Pacote dplyr: fun√ß√µes select() e filter() ‚úÖ
    - Exerc√≠cios ‚úÖ

- Aula 6 ‚úÖ

    - Fun√ß√£o mutate ‚úÖ
    - Fun√ß√µes group_by e summarize ‚úÖ
    - Exerc√≠cios ‚úÖ

- Aula 7 ‚úÖ

    - Introdu√ß√£o ao Pacote dplyr: Tipos B√°sicos de *joins* ‚úÖ
    - Exerc√≠cios ‚úÖ

- Aula 8 ‚úÖ

    - Avalia√ß√£o 1

- Aula 9 ‚úÖ

    - Modelos ‚úÖ

    - Conceitos Fundamentais de Probabilidade ‚úÖ 

      - O que √© Probabilidade? ‚úÖ
      - Probabilidade Condicional e Independ√™ncia ‚úÖ
      - Amostra Aleat√≥ria ‚úÖ
      - Vari√°veis Aleat√≥rias e Fun√ß√µes de Probabilidade ‚úÖ
      - Fun√ß√£o de Distribui√ß√£o Acumulada ‚úÖ
      - Lei dos Grandes N√∫meros ‚úÖ
  
    - Distribui√ß√µes de Probabilidade de VA Discretas ‚úÖ
    
      - Distribui√ß√£o de Bernoulli ‚úÖ
      - Caracter√≠sticas de uma Distribui√ß√£o de Probabilidade ‚úÖ
    
        - Valor Esperado ‚úÖ
        - Vari√¢ncia e Desvio-Padr√£o ‚úÖ
        - Assimetria e Curtose ‚úÖ
    
    - Distribui√ß√£o Binomial ‚úÖ

- Aula 10 ‚úÖ

    - Distribui√ß√µes de Probabilidade de VA Cont√≠nuas ‚úÖ
    
        - Distribui√ß√£o Uniforme ‚úÖ
        - M√©todo da Transforma√ß√£o Invesa da FDA ‚úÖ
        - Distribui√ß√£o Normal ‚úÖ
        - Teorema Central do Limite ‚úÖ
        - Fundamentos de Simula√ß√£o de Monte Carlo ‚úÖ
        - Distribui√ß√£o Conjunta de Vari√°veis Aleat√≥rias ‚úÖ
        - Distribui√ß√£o Condicional ‚úÖ 
        - Distribui√ß√£o Marginal ‚úÖ
        - Independ√™ncia de Vari√°veis Aleat√≥rias ‚úÖ
        - Covari√¢ncia e Correla√ß√£o ‚úÖ

- Aula 11 ‚úÖ

    - Simula√ß√£o de Monte Carlo - Aplica√ß√µes ‚úÖ

    - Aplica√ß√£o - Valor-em-Risco (VaR) ‚úÖ

      - Pacote tidyquant, S√©ries de Pre√ßos e de Rretornos de Ac√µes ‚úÖ
      - M√©todo Param√©trico ‚úÖ
      - M√©todo Hist√≥rico ‚úÖ
      - M√©todo de Simula√ß√£o de Monte Carlo ‚úÖ

    - Aplica√ß√£o - ES/CVaR ‚úÖ

- Aula 12 ‚úÖ

    - Revis√£o de Matem√°tica B√°sica ‚úÖ
    - Estat√≠stica, Probabilidade e Simula√ß√£o ‚úÖ
    - Par√¢metro, Estimador/Estat√≠stica, Estimativa ‚úÖ
    - M√©todos de Infer√™ncia Estat√≠stica ‚úÖ
    - Estima√ß√£o Pontual de Par√¢metros Populacionais ‚úÖ
      - M√©todo da M√°xima Verossimilhan√ßa ‚úÖ
      - Propriedades de Estimadores ‚úÖ
:::




## Nesta Aula

::: {.callout-note icon=false}
## T√≥picos - Fundamentos de Estat√≠stica e Simula√ß√£o

- M√©todo da M√°xima Verossimilhan√ßa 

  - Informa√ß√£o de Fisher

- Distribui√ß√£o Amostral 

- Estima√ß√£o por Intervalo de Confian√ßa 

:::
 



## 

:::: {style="font-size: 85%;"}

::: callout-tip
## Diretrizes para Aulas Mais Produtivas

‚å®Ô∏è **C√≥digo com m√©todo:**

95% dos erros s√£o evit√°veis com: 

- Aten√ß√£o na digita√ß√£o  
- Respeitar a sequ√™ncia l√≥gica de etapas  
- Revis√£o antes de pedir ajuda  

ü§ù **Intelig√™ncia colaborativa:**  

- Compartilhe conhecimento
- Resolva quest√µes t√©cnicas simples com colegas pr√≥ximos  
- Reserve ao professor as d√∫vidas conceituais complexas  

üí™ **Capacidade de Resolver Problemas**  

Cada erro resolvido √© uma evolu√ß√£o da sua habilidade anal√≠tica  
:::
::::




## O que √© compreender algo?


:::: {.callout-quote icon=false}

"Knowing the name of something is not the same as knowing something."
‚Äî Richard Feynman
::::




## M√©todos de Infer√™ncia Estat√≠stica

::: {.callout-note icon=false}
## Descri√ß√£o

Infer√™ncia estat√≠stica s√£o m√©todos que consistem em usar dados de 
uma amostra para tirar conclus√µes sobre par√¢metros de uma popula√ß√£o 
subjacente da qual a amostra foi retirada.
:::

::: {.callout-note icon=false}
## Escola Frequentista/M√°xima Verossimilhan√ßa

- Estima√ß√£o de Par√¢metros:

    - Pontual ‚úì
    - [Estima√ß√£o por Intervalo de Confian√ßa]{style="color:blue;"}
  
- [Testes de Signific√¢ncia]{style="color:blue;"}
:::




# Estima√ß√£o por M√°xima Verossimilhan√ßa {.center background-color="#F1E9D2"}


## Estimador de M√°xima Verossimilhan√ßa 

::: {.callout-note icon=false}
## Propriedades dos Estimadores de MV

Agora, sabemos que os estimadores de m√°xima verossimilhan√ßa possuem 
boas propriedades:

- Os estimadores de MV s√£o **assintoticamente n√£o viesados**, √† 
medida que que $n$ aumenta, qualque vi√©s do estimador tende a zero.

- Os estimadores de MV s√£o **consistentes**: √† medida que $n$ aumenta, 
o estimador de MV converge para o valor verdadeira do par√¢metro da 
popula√ß√£o.

- Os estimadores de MV s√£o **assintoticamente  eficientes**: para $n$ grande, 
eles possuem menor vari√¢ncia do que outros estimadores.

- A distribui√ß√£o amostral dos estimadores de MV √© **assint√≥ticamente normal**. 
:::




## Estimadores de M√°xima Verossimilhan√ßa

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Resumo

- Seja $Y$ uma vari√°vel aleat√≥ria (discreta ou cont√≠nua) que representa 
um fen√¥meno aleat√≥rio de interesse e que √© modelada por uma 
distribui√ß√†o de probabilidades. 

- Seja $Y = (y_1, y_2,\ldots, y_n)$ uma amostra observada da VA Y, ou seja, 
os dados.

- A distribui√ß√£o de probabilidades de $Y$ √© descrita por um vetor de 
par√¢metros $\theta$ desconhecido os quais, portanto, precisam ser estimados 
usando os dados observados.

- Seja $f(y|\theta)$ a fun√ß√£o de verossimilhan√ßa, que √© proporcional √† 
probabilidade condicional dos dados, condicional ao vetor de par√¢metros 
$\theta$. 

- Os estimadores de MV de $\theta$ s√£o aqueles que 
**maximizam a fun√ß√†o de verossimilhan√ßa**. Ou seja, s√£o os estimadores que 
maximizam a probabilidade de ocorr√™ncia dos dados observados.

- Para encontrar os estimadores de MV de $\theta$, maximizamos a 
**fun√ß√£o de log-verossimilhan√ßa**, por ser computacionalmente 
mais simples.
:::
::::




## Distribui√ß√µes de Bernoulli e Binomial

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Distribui√ß√µes de Bernoulli e Binomial

#### **Distribui√ß√£o de Bernoulli**  

Seja $Y_i\in\{0,1\}$ com probabilidade de sucesso $p$ e de fracasso $1-p$.

$$
P(Y_i = y_i) = p^y(1 - p)^{1 - y} 
$$

#### **Distribui√ß√£o Binomial** ‚Äì $n$ ensaios i.i.d. Bernoulli

$$
Y=\sum_{i=1}^n Y_i\sim\operatorname{Bin}(n,p),\;\;\;P(Y=y)=\binom{n}{y}p^{y}(1-p)^{\,n-y}
$$

$$
E(Y)=np,\qquad V[Y] = np(1-p)
$$

#### **Aplica√ß√µes**

- Econometria: Modelos logit e probit
- Finan√ßas: Modelos Risco de cr√©dito (*default*) 
- Finan√ßas: Precifica√ß√£o de Op√ß√µes  
:::
::::




## Aplica√ß√£o

::: {.callout-note icon=false}
## EMV de $p$

- Nos EUA, uma pesquisa denominada *General Social Survey (GSS)* 
de 2018 perguntou aos participantes: 
‚Äú*Voc√™ acredita que existe vida ap√≥s a morte?*" 

- Entre os 2.123 indiv√≠duos da amostra aleat√≥ria, 1.720 declararam que 
acreditam que h√° vida ap√≥s a morte. 

- Vamos obter o EMV de $p$, a propor√ß√£o de pessoas que acreditam 
que h√° vida ap√≥s a morte. 
:::




## EMV da Probabilidade de Sucesso $p$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Deriva√ß√£o do EMV de $p$

Suponha $k$ amostras independentes $x_1,\ldots,x_k$ de 
$\operatorname{Bin}(n,p)$.

#### Fun√ß√£o de verossimilhan√ßa

Ignorando o termo constante $\binom{n}{x_i}$:

$$
\begin{aligned}
L(p) &= \prod_{i=1}^{k}\binom{n}{x_i}p^{x_i}(1-p)^{n-x_i}, \\
L(p) &\propto \prod_{i=1}^{k} p^{x_i} (1 - p)^{n - x_i} 
\end{aligned}
$$
Portanto, a fun√ß√£o de log‚Äëverossimilhan√ßa √©:

$$
\log L(p) = \sum_{i=1}^k\bigl[x_i\,\log p+(n-x_i)\,\log(1-p)\bigr]
$$

#### Condi√ß√£o de 1¬™ ordem (score)

$$
\frac{\partial \log L(p)}{\partial p}=\frac{\sum x_i}{p}-\frac{kn-\sum x_i}{1-p} = 0
$$

Multiplicando por $p(1-p)$ e isolando $p$:

$$
\hat p = \frac{\sum x_i}{kn}=\bar x
$$

#### Condi√ß√£o de 2¬™ ordem

$$
\frac{\partial^{2} \log L(p)}{\partial p^{2}}=-\frac{\sum x_i}{p^{2}}-\frac{kn-\sum x_i}{(1-p)^{2}}<0
$$

Logo $\hat p$ maximiza $L(p)$.
:::
::::




## EMV de $p$

::: {.callout-tip}
## Usando a Linguagem R

- Vamos obter o EMV de $p$, a propor√ß√£o de pessoas que acreditam 
que h√° vida ap√≥s a morte usando R. 

- Al√©m disso, vamos visualizar a fun√ß√£o de verossimilhan√ßa e a fun√ß√£o 
de log-verossimilhan√ßa
:::




## O Exemplo anterior em R

```{r}
#| echo: true
#| output-location: slide

# Fun√ß√£o para plotar a fun√ß√£o de verossimilhan√ßa e a fun√ß√£o de log-verossimilhan√ßa
plot_funcao_mv = function(y,n)
{
    L <-  function(p) dbinom(y,n,p)
    emv <- optimize(L, interval = c(0,1), maximum = TRUE)$max
    p <-  (1:100)/100

    # graficos da funcao de MV e de Log-MV
    par(mfrow = c(1,1))
    plot(p, L(p), type = 'l')
    abline(v = emv)
    plot(p, log(L(p)), type = 'l')
    abline(v = emv)
    round(emv, 2)
}
plot_funcao_mv(1720,2123)
```




## Curvatura da Fun√ß√£o de Log‚ÄëVerossimilhan√ßa

::: {.callout-tip}
## Resumo

- A **curvatura da fun√ß√£o de log-verossimilhan√ßa** cont√©m 
**todas as informa√ß√µes**  que os **dados** fornecem sobre um vetor de 
**par√¢metros** $\theta$, dado o modelo. 

- Vamos entender o porqu√™ disso. A maior parte da Estat√≠sica moderna 
pode ser aprendida com um bom dom√≠nio destes conceitos 
cr√≠ticos.

- Vejamos alguns formatos poss√≠veis da curvatura da fun√ß√£o de 
log-verossimilhan√ßa ($\ln f(X|\theta)$) em rela√ß√£o √† $\theta$.
:::




## Informa√ß√£o de Fisher $I(p)$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Curvatura da Fun√ß√£o de Log‚ÄëVerossimilhan√ßa

A **Informa√ß√£o de Fisher** √© uma maneira de medir a quantidade de 
informa√ß√£o que uma amostra de uma VA $Y$ cont√©m sobre um par√¢metro 
desconhecido $\theta$ da distribui√ß√£o de probabilidade de $Y$. 
**Por qu√™?**

![Curvatura da Fun√ß√£o de Log-Verossimilhan√ßa](img/loglik_curvatura.jpeg){#fig-curvaloglig fig-align="center"}

- Se a curvatura de $\log L(\theta)$ em rela√ß√£o √†s varia√ß√µes de 
$\theta$ √© **pequena**, h√° muitos valores de $\theta$ que produzem 
valores de $\log L(\theta)$ pr√≥ximos. 

  - Neste caso, a informa√ß√£o sobre o valor de $\theta$ √© **vaga ou pequena**. 

- Se a curvatura de $\log L(\theta)$ √© **grande** 
em rela√ß√£o √†s varia√ß√µes em $\theta$, √© mais prov√°vel encontrar o valor 
"correto" de $\theta$ usando os dados, pois h√° mais probabilidade 
concentrada em torno de $\theta$. 

  - Neste caso, a informa√ß√£o sobre o valor de $\theta$ √© **grande**.
  
- Isso sugere estudar algum tipo de **vari√¢ncia** em rela√ß√£o ao vetor 
de par√¢metros $\theta$. Essa √© a motiva√ß√£o para a Informac√£o de Fisher.
:::
::::




## Informa√ß√£o de Fisher $I(p)$ 

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Informa√ß√£o de Fisher

- A resposta refere-se ao conceito de **Informa√ß√£o de Fisher**.

- Em Estat√≠stica, a **Informa√ß√£o de Fisher** √© uma maneira de 
medir a quantidade de informa√ß√£o que uma amostra de uma vari√°vel aleat√≥ria 
$Y$ cont√©m sobre um par√¢metro desconhecido $\theta$ de uma distribui√ß√£o de 
probabilidade que modela $Y$.

Se o score √© dado $S(p) = \dfrac{\partial \log L(p)}{\partial p}$, 
a informa√ß√£o de Fisher √© definida como **vari√¢ncia** do score:

$$
I(p) = -E\bigl[S(p)^{2}\bigr] = -E\Bigl[\frac{\partial^{2} \log L(p)}{\partial p^{2}}\Bigr]=\frac{kn}{p(1-p)}
$$

- Quanto mais amostras, mais informa√ß√£o acumulada ‚Äî o numerador √© $kn$

#### Por que tomar o valor esperado?

- Como a fun√ß√£o de log-verossimilhan√ßa depende dos 
**dados espec√≠ficos observados**,  a segunda derivada de $\log L(\theta)$ 
tamb√©m depende da amostra.

- Mas a Informa√ß√£o de Fisher quer medir quanta informa√ß√£o uma 
**distribui√ß√£o** (n√£o uma amostra espec√≠fica) fornece sobre $\theta$.

Ent√£o usamos:

* O **Valor Esperado** da derivada segunda, tomada sobre a distribui√ß√£o 
dos dados, assumindo que $\theta$ √© o valor verdadeiro.

* Isso nos d√° uma **medida m√©dia** da curvatura, que independe 
de uma amostra espec√≠fica.
:::
::::




## Informa√ß√£o de Fisher

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Aplica√ß√µes Atuais

#### 1. Rob√≥tica: Localiza√ß√£o e Mapeamento (SLAM)

- Em sistemas de **rob√≥tica m√≥vel**, a Informa√ß√£o de Fisher quantifica 
**quanto um sensor contribui para estimar a posi√ß√£o do rob√¥**.

- √â usada para **planejar trajet√≥rias que maximizem a informa√ß√£o esperada**, otimizando o processo de **localiza√ß√£o e mapeamento simult√¢neos (SLAM)** [@Carrillo2012].

#### 2. Aprendizado de M√°quina: Otimiza√ß√£o com *Natural Gradient Descent*

- O objetivo √© **acelerar e estabilizar o treinamento de modelos complexos**, 
como redes neurais profundas.

- A matriz da Informa√ß√£o de Fisher define uma 
**m√©trica no espa√ßo dos par√¢metros**, refletindo a geometria da fun√ß√£o 
de perda.

- O m√©todo do **gradiente natural** utiliza essa m√©trica para atualizar 
os par√¢metros em dire√ß√µes mais informativas, levando em conta a curvatura 
local.

- Isso resulta em **converg√™ncia mais r√°pida**, evitando instabilidades 
comuns em otimiza√ß√£o com gradiente padr√£o [@Amari1998; @Martens2020].

:::
::::





# Distribui√ß√£o Amostral {.center background-color="#F1E9D2"}


## O que √© uma Distribui√ß√£o Amostral?

:::: {style="font-size: 100%;"}

::: {.callout-note icon=false}
## Distribui√ß√£o Amostral

- Um **estimador** (ou **estat√≠stica**) $T(Y)$ √© uma fun√ß√£o dos dados 
da amostra.

- Antes da coleta dos dados, $T$ √© uma **vari√°vel aleat√≥ria** ‚Äî seus 
valores poss√≠veis seguem uma **distribui√ß√£o de probabilidade**.

- Essa distribui√ß√£o √© chamada de **distribui√ß√£o amostral do estimador**.

- A distribui√ß√£o amostral descreve:

  - A **variabilidade** do estimador entre diferentes amostras.
  - O **valor esperado** e a **precis√£o** do estimador em rela√ß√£o ao 
  par√¢metro populacional.

> A **infer√™ncia estat√≠stica** baseia-se nessa distribui√ß√£o para estimar 
par√¢metros e quantificar incertezas.
:::
::::




## Distribui√ß√£o de $\hat{p}$ (Propor√ß√£o Amostral)

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Dois Casos

#### Amostra pequena ($n$ pequeno)

$$
\hat{p} = \frac{Y}{n}, \quad \text{com } Y \sim \operatorname{Bin}(n, p)
$$

- $Y$ representa o **n√∫mero de sucessos** em $n$ tentativas independentes, 
com probabilidade $p$ de sucesso (modelo Bernoulli).

- Assim, $Y$ segue uma **distribui√ß√£o binomial**, e $\hat{p}$, sendo $Y/n$, 
tem uma distribui√ß√£o **escalada da binomial**.

- A distribui√ß√£o de $\hat{p}$ √© **discreta**, e sua forma depende de $n$ e $p$.

- Propriedades:  

  $E(\hat{p}) = p$,  
  $V(\hat{p}) = \dfrac{p(1 - p)}{n}$

#### Amostra grande ($n \to \infty$)

- Pelo **Teorema Central do Limite**, a distribui√ß√£o de $\hat{p}$ 
aproxima-se de uma normal:

$$
\hat{p} \;\dot{\sim}\; N\!\left(p,\;\dfrac{p(1 - p)}{n}\right)
$$

> Aproxima√ß√£o v√°lida se $np > 10$ e $n(1 - p) > 10$.
:::
::::




## Distribui√ß√£o da M√©dia Amostral $\bar{X}$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Defini√ß√£o e Propriedades

A **m√©dia amostral** $\bar{X}$ √© definida como:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i
$$

onde $X_1, \dots, X_n$ s√£o observa√ß√µes independentes e identicamente 
distribu√≠das (i.i.d.), com m√©dia $\mu$ e vari√¢ncia $\sigma^2$.

#### Propriedades:

- **Valor esperado:**  

  $$ E(\bar{X}) = \mu $$  
  - $\bar{X}$ √© um **estimador n√£o-viesado** de $\mu$.

- **Vari√¢ncia:**  

  $$ V(\bar{X}) = \frac{\sigma^2}{n} $$  
  - A variabilidade da m√©dia diminui com o tamanho da amostra.

- **Erro-padr√£o:**  

  $$ \operatorname{EP}(\bar{X}) = \frac{\sigma}{\sqrt{n}} $$  
  - Mede a incerteza da estimativa de $\mu$ com base em uma amostra de 
tamanho $n$.
:::
::::




## Teorema Central do Limite (TCL) e a M√©dia Amostral

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## O que diz o TCL?

Seja $X_1, \dots, X_n$ uma amostra aleat√≥ria de uma popula√ß√£o com m√©dia 
$\mu$ e desvio padr√£o $\sigma$.

Mesmo que a distribui√ß√£o da popula√ß√£o **n√£o seja normal**, a 
**distribui√ß√£o da m√©dia amostral** $\bar{X}$ se aproxima de uma normal 
quando $n$ √© grande.

#### Resultado:

$$
\frac{\sqrt{n}(\bar{X} - \mu)}{\sigma}\;\xrightarrow{d}\; N(0, 1)
$$

Ou equivalentemente:

$$
\bar{X} \;\dot{\sim}\; N\left(\mu, \frac{\sigma^2}{n} \right)
$$

#### Condi√ß√µes para aplicar o TCL:

- Amostra aleat√≥ria e observa√ß√µes independentes.  
- Tamanho amostral suficientemente grande.  

> Regra pr√°tica: $n \gtrsim 30$ geralmente √© suficiente, especialmente se a popula√ß√£o n√£o for muito assim√©trica ou com outliers.
:::
::::




## Teorema Central do Limite

![Independente da forma da distribui√ß√£o da popula√ß√£o, na medida que $n$ aumenta, a Distribui√ß√£o Amostral de $\bar{X}$ torna-se mais estreita e converge para uma distribui√ß√£o normal.](img/tcl.jpeg){fig-align="center"}




## Variabilidade da Distribui√ß√£o Amostral

:::: {style="font-size: 95%;"}
::: {.callout-note icon=false}
## Erro‚ÄëPadr√£o (EP)

- O **erro-padr√£o** √© o desvio padr√£o da distribui√ß√£o amostral de 
um estimador.  

  - Mede a **variabilidade do estimador** devida √† **aleatoriedade da amostragem**.

- Um erro-padr√£o menor indica um estimador **mais preciso**.

- Fatores que afetam o erro-padr√£o:  

  - **Variabilidade dos dados na popula√ß√£o**: quanto maior $\sigma^2$ ou 
   $p(1 - p)$, maior o erro-padr√£o.  
   
  - **Tamanho da amostra** ($n$): quanto maior $n$, menor o erro-padr√£o.

> Obs.: ‚ÄúPopula√ß√£o‚Äù refere-se ao conjunto total de onde as amostras s√£o 
extra√≠das.
:::
::::




## M√©todo Delta

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Vis√£o Geral

O **Teorema Central do Limite** mostra que muitas estat√≠sticas amostrais t√™m distribui√ß√£o aproximadamente normal quando a amostra √© grande.

O **M√©todo Delta** estende esse resultado para **fun√ß√µes n√£o lineares** 
dessas estat√≠sticas.


#### Vers√£o Simplificada:

Seja $T$ um estimador de um par√¢metro $\theta$, tal que:

$$
\sqrt{n}(T - \theta) \overset{d}{\longrightarrow} N(0, \tau^2)
$$

e seja $g(\cdot)$ uma fun√ß√£o diferenci√°vel em $\theta$, ent√£o:

$$
\sqrt{n}\left[g(T) - g(\theta)\right] \overset{d}{\longrightarrow} 
N\left(0,\, [g'(\theta)]^2 \cdot \tau^2 \right)
$$


#### Interpreta√ß√£o:

- Se $T$ √© assintoticamente normal, ent√£o **qualquer fun√ß√£o suave de $T$** 
tamb√©m ser√° assintoticamente normal.

- A vari√¢ncia de $g(T)$ depende da inclina√ß√£o (derivada) de $g$ no ponto 
$\theta$.

- Permite aproximar distribui√ß√µes amostrais de transforma√ß√µes como 
$\log(T)$, $\exp(T)$, $1/T$, etc.


#### Aplica√ß√µes:

- Constru√ß√£o de intervalos de confian√ßa para transforma√ß√µes de estimadores.  
- Justificativa te√≥rica para testes e estimadores n√£o-lineares.  
:::
::::





# Estima√ß√£o por Intervalo de Confian√ßa {.center background-color="#F1E9D2"}


## Por que Intervalos de Confian√ßa?

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## O Desafio do Analista de Dados

**Problema**: Uma estimativa pontual informa um valor, mas **n√£o** quantifica a incerteza associada √† infer√™ncia de uma amostra para a popula√ß√£o.

**Exemplo**: Satisfa√ß√£o m√©dia de 7.2 pontos em amostra de 100 clientes.

**Pergunta**: Qual a **precis√£o** desta estimativa?

**Solu√ß√£o**: Intervalos de confian√ßa n√£o reduzem a incerteza, mas 
**quantificam a incerteza da amostragem**, fornecendo um intervalo onde 
o par√¢metro populacional provavelmente se encontra.

**Comunica√ß√£o Correta**: 

> "A satisfa√ß√£o m√©dia de todos os clientes est√° entre 6.8 e 7.6 pontos, 
com 95% de confian√ßa."

Quantifica a incerteza da amostragem.
:::
::::




## Import√¢ncia da Amostragem Aleat√≥ria

:::: {style="font-size: 95%;"}

::: {.callout-important icon=false}
## **Por que a aleatoriedade √© importante?**

Os intervalos de confian√ßa assumem que os dados prov√™m de uma 
**amostra aleat√≥ria** da popula√ß√£o de interesse. Esta condi√ß√£o √© 
fundamental para a validade dos resultados.

**Consequ√™ncias da aleatoriedade**:

- Garante que cada elemento da popula√ß√£o tenha chance conhecida de sele√ß√£o
- Permite que as propriedades probabil√≠sticas dos estimadores sejam v√°lidas
- Assegura que os intervalos tenham as propriedades de cobertura desejadas

**Responsabilidade do analista**: Sempre verificar e documentar o m√©todo de amostragem utilizado, alertando sobre limita√ß√µes quando a aleatoriedade n√£o 
for garantida.
:::
::::




## Estima√ß√£o por Intervalo de Confian√ßa

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
#### Defini√ß√£o Formal

Sejam $T_L(Y)$ e $T_U(Y)$ duas fun√ß√µes dos dados amostrais 
$Y = (y_1, \dots, y_n)$ tais que:

$$
P\left[ T_L(Y) \leq \theta \leq T_U(Y) \right] = 1 - \alpha, \quad \text{para todo } \theta
$$

Ap√≥s a observa√ß√£o dos dados, o intervalo $[T_L(Y), T_U(Y)]$ √© chamado 
de **intervalo de confian√ßa** de n√≠vel $1 - \alpha$.


#### Confian√ßa vs. Probabilidade

- A probabilidade $1 - \alpha$ se refere ao processo aleat√≥rio de 
gera√ß√£o dos dados, n√£o ao par√¢metro $\theta$.

- Ap√≥s observar os dados, o intervalo cont√©m ou n√£o $\theta$. Mas, antes da observa√ß√£o, o intervalo √© aleat√≥rio.

- A interpreta√ß√£o √© frequentista: $\theta$ √© fixo; o intervalo √© 
vari√°vel.
:::
::::




## Intervalos de Confian√ßa 

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Interpreta√ß√£o Formal

- Um intervalo com 95\% de confian√ßa, por exemplo, implica que, se fossem 
retiradas 100 amostras e fossem obtidas 100 estimativas por IC, 
espera-se que 95\% dos intervalos calculados contenham o valor 
verdadeiro do par√¢metro.

- A @fig-ics ilustra, mostrando 100 estimativas de IC 
$[TL(y), TU(y)]$ para um par√¢metro $\theta$, com base em 100 amostras 
extra√≠das alguma popula√ß√£o. Os 5 intervalos em vermelho n√£o incluem $\theta$. 


![Intervalos de confian√ßa de 95% para um par√¢metro $\theta$ com base em 
100 amostras separadas de uma popula√ß√£o. Os intervalos de confian√ßa em 
vermelho s√£o aqueles que n√£o incluem $\theta$.](img/ics.jpeg){#fig-ics}
:::
::::




## Estimador por IC para $p$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Constru√ß√£o de um Estimador por IC para $p$

Segundo Fisher, sob algumas condi√ß√µes, a distribui√ß√£o assint√≥tica 
do **estimador de m√°xima verossimilhan√ßa (EMV)** √©:

$$
\hat{\theta} \overset{d}{\longrightarrow} \mathcal{N}\left(\theta, \frac{1}{I(\theta)}\right)
$$

Isso implica que a **vari√¢ncia assint√≥tica** do EMV √© inversamente 
proporcional √† **informa√ß√£o de Fisher**:

$$
\operatorname{Var}(\hat{\theta}) \approx \frac{1}{I(\theta)}
$$

Assim, a fun√ß√£o de log-verossimilhan√ßa n√£o serve apenas para encontrar 
$\hat{\theta}$, mas tamb√©m para avaliar sua **precis√£o**.

- Um estimador cuja vari√¢ncia assint√≥tica atinge 
$\frac{1}{I(\theta)}$ √© dito **assintoticamente eficiente**.

Na pr√°tica, como $\theta$ √© desconhecido, estimamos a vari√¢ncia 
substituindo $\theta$ pelo EMV $\hat{\theta}$:

$$
\widehat{\operatorname{Var}}(\hat{\theta}) \approx \frac{1}{I(\hat{\theta})}
$$


#### Aplica√ß√£o: Estimador de $p$ na Binomial

Para $X_1, \dots, X_k \overset{\text{iid}}{\sim} \operatorname{Bin}(n, p)$, 
a informa√ß√£o de Fisher √©:

$$
I(p) = \frac{kn}{p(1 - p)}
$$

Portanto, a vari√¢ncia assint√≥tica do EMV $\hat{p}$ √©:

$$
\operatorname{Var}(\hat{p}) \approx \frac{1}{I(p)} = \frac{p(1 - p)}{kn}
$$

Pela normalidade assint√≥tica, temos:

$$
\hat{p} \overset{d}{\longrightarrow} \mathcal{N}\left(p, \frac{p(1 - p)}{kn}\right)
$$

Ou seja:

- $E(\hat{p}) = p$
- $\operatorname{Var}(\hat{p}) = \dfrac{p(1 - p)}{kn}$
- $\sigma_{\hat{p}} = \sqrt{\dfrac{p(1 - p)}{kn}}$

:::
::::




## Estimador por IC para $p$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## M√©todo da Quantidade Pivotal

Uma **quantidade pivotal** √© uma fun√ß√£o dos dados e do par√¢metro:

$$
Q(X_1, \dots, X_n; \theta)
$$

com distribui√ß√£o conhecida e **independente** de $\theta$.

Se $T(Y) \sim N(\theta, \sigma^2)$, ent√£o:

$$
Z = \frac{T(Y) - \theta}{\sigma} \sim N(0, 1)
$$

#### Construindo o Intervalo com a Quantidade Pivotal

Sabemos que:

$$
P[-1.96 \leq Z \leq 1.96] = 0.95
$$

Se:

$$
Z = \frac{T(Y) - \theta}{\sigma}
$$

ent√£o:

$$
P\left[T(Y) - 1.96\sigma \leq \theta \leq T(Y) + 1.96\sigma \right] = 0.95
$$
:::
::::




## Estimador por IC para $p$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Liga√ß√£o com EMV, Teorema Central do Limite e Fisher

- Pelo **Teorema Central do Limite**, 
$\bar{X} \to \mathcal{N}(\mu, \sigma^2/n)$ para $n$ grande.

Estimadores de m√°xima verossimilhan√ßa (EMV) s√£o 
**assintoticamente normais**:

$$
\hat{\theta} \overset{d}{\rightarrow} \mathcal{N}\left(\theta, \frac{1}{I(\theta)}\right)
$$

Isso nos permite aplicar o **m√©todo da quantidade pivotal** com:

$$
Z = \frac{\hat{\theta} - \theta}{\sigma_{\hat{\theta}}}
$$

Intervalos assint√≥ticos:

$$
\hat{\theta} \pm z_{\alpha/2} \cdot \sigma_{\hat{\theta}}
$$

:::
::::




## Intervalo de Confian√ßa Assint√≥tico para $p$

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Deriva√ß√£o - Intui√ß√£o

Sabemos que:

$$
\hat{p} \overset{d}{\rightarrow} N\left(p, \frac{p(1 - p)}{n}\right)
$$

Logo:

$$
Z = \frac{\hat{p} - p}{\sqrt{\frac{p(1 - p)}{n}}} \to N(0,1)
$$

Aproximamos com $\hat{p}$ no denominador:

$$
\boxed{
\hat{p} \pm z_{\alpha/2} \cdot \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
}
$$

- 95%: $z = 1.96$
- 99%: $z = 2.58$

Exemplos:

- 95%: como 
$\alpha = 0.05 \Rightarrow \alpha/2 = 0.025 \Rightarrow z_{0.025} = 1.96$, 
(em R: `qnorm(1 - 0.025) = qnorm(0.975)`), ent√£o:
  
  $\hat{p} \pm 1.96 \sqrt{\dfrac{\hat{p}(1 - \hat{p})}{n}}$

- 99%: como 
$\alpha = 0.01 \Rightarrow \alpha/2 = 0.005 \Rightarrow z_{0.005} = 2.58$, 
(em R: `qnorm(1 - 0.005) = qnorm(0.995)`), ent√£o:

  $\hat{p} \pm 2.58 \sqrt{\dfrac{\hat{p}(1 - \hat{p})}{n}}$

#### Considera√ß√µes Pr√°ticas

- A normal aproxima bem a binomial se:

$$
np \geq 10 \quad \text{e} \quad n(1 - p) \geq 10
$$

- Caso essas condi√ß√µes n√£o sejam atendidas, intervalos baseados nela podem ter 
n√≠vel de confian√ßa real inferior ao desejado.

- Alternativas incluem m√©todos exatos (Clopper-Pearson) ou 
corre√ß√µes (Wilson, Agresti-Coull).
:::
::::





## Resumo

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Resumo

1. Encontramos o **estimador** $\hat{p}$ pelo **m√©todo da m√°xima verossimilhan√ßa**.

2. Derivamos sua **vari√¢ncia assint√≥tica** com a **informa√ß√£o de Fisher**.

3. Aplicamos o **TCL** para obter a **distribui√ß√£o amostral** de $\hat{p}$.

4. Usamos o **m√©todo da quantidade pivotal** para construir um intervalo 
de confian√ßa.


#### Intervalos de Confian√ßa para $p$:

- **Para amostras grandes (m√©todo de Wald):**

$$
\boxed{
\hat{p} \pm z_{\alpha/2} \cdot \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
}
$$

Para **$n$ pequeno** ou $\hat{p}$ pr√≥ximo de 0 ou 1, pode ser imprecisa.

- **Para amostras pequenas (intervalo exato de Clopper‚ÄìPearson):**

Usado, por exemplo, na fun√ß√£o `binom.test()` do R. Baseia-se na 
distribui√ß√£o binomial e fornece cobertura exata.
:::
::::



## IC para uma ou duas propor√ß√µes

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Resumo

|                       | **Uma Propor√ß√£o**                             | **Duas Propor√ß√µes**                                       |
|-----------------------|-----------------------------------------------|------------------------------------------------------------|
| **Suposi√ß√µes**        | Amostra aleat√≥ria, vari√°vel bin√°ria           | Amostras aleat√≥rias independentes, vari√°veis bin√°rias      |
| **Par√¢metro**         | $p$                                           | $p_1 - p_2$                                                |
| **Estimador**         | $\hat{p} = \dfrac{Y}{n}$                      | $\hat{p}_1 = \dfrac{Y_1}{n_1},\; \hat{p}_2 = \dfrac{Y_2}{n_2}$ |
| **Quantidade pivotal**| $z = \dfrac{\hat{p} - p}{EP}$                 | $z = \dfrac{(\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)}{EP}$     |
| **Erro-padr√£o (Wald)**| $\sqrt{\dfrac{\hat{p}(1 - \hat{p})}{n}}$      | $\sqrt{\dfrac{\hat{p}_1(1 - \hat{p}_1)}{n_1} + \dfrac{\hat{p}_2(1 - \hat{p}_2)}{n_2}}$ |
| **IC (Wald)**         | $\hat{p} \pm z_{\alpha/2} \cdot EP$           | $(\hat{p}_1 - \hat{p}_2) \pm z_{\alpha/2} \cdot EP$         |
:::
::::




## Fun√ß√µes R para IC para Propor√ß√µes

:::: {style="font-size: 85%;"}

::: {.callout-note icon=false}
## prop.test() e binom.test()

**`prop.test()`**

- Usa a distribui√ß√£o **qui-quadrado** com **corre√ß√£o de continuidade de Yates**
- Intervalo √© geralmente **mais conservador** do que o m√©todo de Wald
- Adequado para amostras grandes ($n \geq 30$)
- Sintaxe: `prop.test(x, n, conf.level = 0.95)`
- Para duas propor√ß√µes: `prop.test(c(x1, x2), c(n1, n2))`

**`binom.test()`**: 

- Intervalo **exato** com base na distribui√ß√£o binomial
- Adequado para amostras pequenas ou quando se deseja **precis√£o m√°xima**
- Sintaxe: `binom.test(x, n, conf.level = 0.95)`
- Apenas para uma propor√ß√£o

**Argumentos**:

- `x`: n√∫mero de sucessos observados  
- `n`: tamanho da amostra  
- `conf.level`: n√≠vel de confian√ßa (padr√£o: 0.95)

**Recomenda√ß√µes**:

- Para $n \geq 30$ e propor√ß√µes longe de 0 ou 1, `prop.test()` √© uma 
escolha pr√°tica e confi√°vel  

- Para amostras pequenas ou propor√ß√µes extremas, prefira `binom.test()` 
para maior precis√£o
:::
::::




## Intervalos de Confian√ßa para uma ou duas m√©dias

:::: {style="font-size: 95%;"}

::: {.callout-note icon=false}
## Resumo


|                       | **Uma M√©dia**                                | **Duas M√©dias**                                                                 |
|-----------------------|----------------------------------------------|----------------------------------------------------------------------------------|
| **Suposi√ß√µes**        | Amostra aleat√≥ria, popula√ß√£o normal          | Amostras aleat√≥rias, popula√ß√µes normais                                          |
|                       |                                              | (vari√¢ncias iguais ou n√£o)                                                      |
| **Par√¢metro**         | $\mu$                                        | $\mu_1 - \mu_2$                                                                 |
| **Estimador**         | $\bar{Y}$                                    | $\bar{Y}_1 - \bar{Y}_2$                                                         |
| **Quantidade pivotal**| $t = \dfrac{\bar{Y} - \mu}{EP}$              | $t = \dfrac{(\bar{Y}_1 - \bar{Y}_2) - (\mu_1 - \mu_2)}{EP}$                      |
| **Erro-padr√£o (EP)**  | $\dfrac{s}{\sqrt{n}}$                        | Com vari√¢ncias **iguais**:                                                      |
|                       |                                              | $\quad s_p \cdot \sqrt{\dfrac{1}{n_1} + \dfrac{1}{n_2}}$                         |
|                       |                                              | $\quad s_p^2 = \dfrac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}$           |
|                       |                                              | Com vari√¢ncias **desiguais** (Welch):                                           |
|                       |                                              | $\quad \sqrt{\dfrac{s_1^2}{n_1} + \dfrac{s_2^2}{n_2}}$                           |
| **IC (geral)**        | $\bar{Y} \pm t_{\alpha/2}(EP)$               | $(\bar{Y}_1 - \bar{Y}_2) \pm t_{\alpha/2}(EP)$                                  |
| **Distribui√ß√£o t**    | gl = $n - 1$                                 | gl = $n_1 + n_2 - 2$ (iguais) ou Welch (desiguais)                              |
:::
::::




## Fun√ß√£o R para Intervalos de Confian√ßa de M√©dias 

::: {.callout-note icon=false}
## Fun√ß√£o t.test()

**t.test()**: Implementa intervalos de confian√ßa e testes de 
signific√¢ncia para m√©dias.

**Para uma m√©dia**:

```{r style="font-size: 1.4em;"}
#| eval: false
t.test(dados, conf.level = 0.95)
```

**Para duas m√©dias (amostras independentes)**:

```{r style="font-size: 1.4em;"}
#| eval: false
t.test(grupo1, grupo2, conf.level = 0.95)
```

**Para duas amostras pareadas**:

```{r style="font-size: 1.4em;"}
#| eval: false
t.test(antes, depois, paired = TRUE, conf.level = 0.95)
```

**Argumentos**:

- `conf.level`: n√≠vel de confian√ßa (padr√£o 0.95)
- `var.equal`: assumir vari√¢ncias iguais (padr√£o FALSE, usa corre√ß√£o de Welch)
- `paired`: para amostras pareadas

**Extra√ß√£o de resultados**: Use `resultado$conf.int` para 
obter apenas o intervalo.
:::




## Aplica√ß√£o 1

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Estima√ß√£o de Intervalo de Confian√ßa para uma Propor√ß√£o

- Uma pesquisa do Eurobar√¥metro de 2019 relatou que a porcentagem de 
pessoas que s√£o ate√≠stas ou agn√≥sticas varia na Europa Ocidental entre 9% 
na Irlanda e 52% na Holanda.

- Intervalos de confian√ßa mostram a precis√£o dessas estimativas. 

- Vamos obter uma estimativa por intervalo de confian√ßa da propor√ß√£o de 
holandeses que s√£o ate√≠stas ou agn√≥sticos para o caso da Holanda, onde 
dos 1.497 entrevistados, 778 relataram ser ateus ou agn√≥sticos.

```{r}
# n√∫mero total de entrevistados na Holanda
n <- 1497

# n√∫mero de entrevistados que relataram ser ateus ou agn√≥sticos
x <- 778

# Intervalo para p
ic_holanda <- binom.test(x, n, conf.level = 0.95)
ic_holanda

# Obtendo somente a estimativa por intervalo de confian√ßa
round(ic_holanda$conf.int, 2)
```

#### Reportando o resultado

A propor√ß√£o de holandeses que se declararam ateus ou 
agn√≥sticos na pesquisa foi de 0,42 (IC 95% [0,49 0.55]), indicando que, 
com 95% de confian√ßa, a verdadeira propor√ß√£o de holandeses que se declaram 
ate√≠stas ou agn√≥sticos est√° entre 49% e 55%.
:::
::::




## Aplica√ß√£o 2

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Estima√ß√£o de Intervalo de Confian√ßa para Comparar Duas Propor√ß√µes

- A pesquisa realizada por @benson2006 utilizou pacientes de seis hospitais 
dos EUA que iriam receber cirurgia de revasculariza√ß√£o do mioc√°rdio. 
Os pacientes foram aleatoriamente designados para dois grupos. 

- Para um grupo, os crist√£os, os volunt√°rios foram instru√≠dos a orar por 
uma cirurgia bem-sucedida com uma recupera√ß√£o r√°pida e saud√°vel e sem 
complica√ß√µes. 

- A ora√ß√£o come√ßou na noite anterior √† cirurgia e continuou por duas
semanas. O outro grupo n√£o teve volunt√°rios orando por eles. 

- A resposta foi se complica√ß√µes m√©dicas ocorreram dentro de 30 dias da 
cirurgia.

- A tabela a seguir sumariza os resultados:

```
        Complications
        -------------
Prayer   Yes   No       Total
Yes      315   289      604
No       304   293      597
```

- Seja $p_1$ a propor√ß√£o de complica√ß√µes para os pacientes 
que tinham um grupo de ora√ß√£o.

- Seja $p_2$ a propor√ß√£o de complica√ß√µes para os pacientes que 
n√£o tinham um grupo de ora√ß√£o.

- Essas s√£o propor√ß√µes populacionais para a popula√ß√£o conceitual que esse exemplo representa.

- Da tabela anterior, as propor√ß√µes amostrais ($\hat p_1$, $\hat p_2$) que 
tiveram complica√ß√µes s√£o:

$$
\hat{p}_1 = \frac{315}{604} = 0,522, \,\, \hat{p}_2 = \frac{304}{597} = 0,509
$$

Agora podemos usar a linguagem R para obter um IC para a diferen√ßa entre 
$p_1 - p_2$:

```{r}
# n√∫mero total de pacientes no grupo de ora√ß√£o
n1 <- 604

# n√∫mero de pacientes que tiveram complica√ß√µes no grupo de ora√ß√£o
x1 <- 315

# n√∫mero total de pacientes no grupo sem ora√ß√£o
n2 <- 597

# n√∫mero de pacientes que tiveram complica√ß√µes no grupo sem ora√ß√£o
x2 <- 304

# Intervalo para p1 - p2
ic_oracao <- prop.test(x = c(x1, x2), n = c(n1, n2), conf.level = 0.95) 
ic_oracao

# Obtendo somente a estimativa por intervalo de confian√ßa
round(ic_oracao$conf.int, 2)
```

#### Reportando o resultado

- A diferen√ßa na propor√ß√£o de pacientes que tiveram complica√ß√µs entre o 
grupo de pacientes que contaram com um grupo de ora√ß√£o (52%) e o 
grupo controle (51%) foi de 0,01 (IC 95% [-0.05, 0.07]), indicando que, com 
95% de confian√ßa, a verdadeira diferen√ßa na propor√ß√£o de complica√ß√µes entre 
os grupos est√° entre -0.05 e 0,07.

- Visto que o intervalo de confian√ßa **cont√©m zero**, os dados da pesquisa 
fornecem evid√™ncia de que n√£o h√° diferen√ßa estatisticamente significativa 
na propor√ß√£o de complica√ß√µes entre os grupos.
:::
::::




## Aplica√ß√£o: Testes A/B

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Experimento Controlado 

- **Defini√ß√£o:**

Um teste A/B √© um experimento que compara duas estrat√©gias ou abordagens 
diferentes dividindo aleatoriamente a popula√ß√£o-alvo em dois grupos: 
controle (vers√£o A) e tratamento (vers√£o B).

- **Metodologia:**

Ambas as vers√µes s√£o apresentadas simultaneamente para grupos similares, 
mantendo constantes todas as demais vari√°veis. Esta abordagem isola o 
efeito espec√≠fico da mudan√ßa testada.

- **Preval√™ncia no Mercado Atual:**

Testes A/B tornaram-se pr√°tica padr√£o em empresas digitais e organiza√ß√µes 
orientadas por dados. Grandes corpora√ß√µes como Google, Amazon, Netflix e 
Facebook executam milhares de testes A/B simultaneamente para otimizar 
continuamente suas plataformas e servi√ßos.

- **Exemplos Reais de Aplica√ß√£o:**

O Netflix testa diferentes thumbnails para filmes e s√©ries para maximizar 
cliques. O Google experimenta varia√ß√µes na apresenta√ß√£o de resultados 
de busca para melhorar a experi√™ncia do usu√°rio. Empresas de e-commerce 
testam cores de bot√µes de compra, formul√°rios de checkout e estrat√©gias 
de frete gr√°tis para aumentar convers√µes.

- **An√°lise Estat√≠stica:**

Intervalos de confian√ßa para diferen√ßa entre propor√ß√µes ou m√©dias 
determinam se as diferen√ßas observadas representam efeitos reais ou 
varia√ß√£o aleat√≥ria.
:::
::::




## Aplica√ß√£o: Teste A/B

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Teste de Duas Vers√µes de Website

**Cen√°rio**: Comparar tempo m√©dio de perman√™ncia entre 
vers√£o atual (A) e redesenhada (B).

```{r style="font-size: 1.4em;"}

# cria dois vetores para os tempos de perman√™ncia
versao_a <- c(3.2, 4.1, 2.8, 3.9, 3.5, 4.3, 2.9, 3.7, 4.0, 3.3,
              2.6, 3.8, 4.2, 3.1, 3.6, 2.7, 4.5, 3.4, 2.5, 3.9)

versao_b <- c(4.8, 5.2, 4.3, 5.6, 4.7, 5.1, 4.9, 5.4, 4.5, 5.0,
              4.6, 5.3, 4.4, 5.7, 4.8, 5.5, 4.2, 5.8, 4.7, 5.2)

# cria uma df para armazenar os dados
dados_ab <- data.frame(
  tempo = c(versao_a, versao_b),
  grupo = c(rep("A", 20), rep("B", 20))
)

# gr√°fico quantil-quantil (QQ) para verificar normalidade
ggqqplot(dados_ab, x = "tempo", color = "grupo") +
  labs(title = "Verifica√ß√£o de Normalidade por Grupo")
```

0 gr√°fico quantil-quantil (QQ) mostra que ambos os grupos 
est√£o razoavelmente pr√≥ximos de uma distribui√ß√£o normal.

```{r style="font-size: 1.4em;"}
# estimativa por ic para diferen√ßa das m√©dias
resultado_ab <- t.test(versao_b, versao_a, conf.level = 0.95)
resultado_ab$conf.int
```

**Resultado**: IC 95% para (B - A) = [1.14, 1.83] minutos, como a estimativa 
por intervalo de confian√ßa para a diferen√ßa entre as m√©dias **n√£o cont√©m** 
zero, podemos concluir que a nova vers√£o (B) √© significativamente 
melhor que a vers√£o atual (A) em termos de tempo m√©dio de perman√™ncia.

**Conclus√£o**: Com 95% de confian√ßa, a nova vers√£o aumenta o tempo m√©dio de perman√™ncia entre **1.14 e 1.83 minutos**.

**Decis√£o**: Implementar Vers√£o B em produ√ß√£o.
:::
::::




## Verifica√ß√£o de Normalidade com Gr√°fico QQ

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Como Interpretar um Gr√°fico Quantil-Quantil

**Objetivo**: Verificar se os dados seguem distribui√ß√£o 
aproximadamente normal.

**Como criar**:

```{r style="font-size: 1.4em;"}
#| eval: false
library(ggpubr)
ggqqplot(dados, x = "variavel")
```

**Como interpretar**:

* **Linha diagonal**: distribui√ß√£o normal te√≥rica
* **Pontos**: quantis observados dos dados
* **Banda cinza**: regi√£o de refer√™ncia baseada em quantis simulados 
de uma normal ‚Äî serve como refer√™ncia visual, **n√£o** como intervalo 
de confian√ßa formal

**Sinais de normalidade adequada**:

* Pontos pr√≥ximos √† linha diagonal
* Maioria dentro da banda cinza
* Padr√£o aproximadamente linear

**Problemas comuns**:

* Curvaturas (assimetria)
* Padr√£o em S (caudas pesadas ou leves)
* Muitos pontos fora da regi√£o de refer√™ncia

**Regra pr√°tica**: Para $n \geq 30$, o Teorema Central do 
Limite garante que pequenas viola√ß√µes da normalidade s√£o aceit√°veis.
:::
::::




## Aplica√ß√£o 3

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Estima√ß√£o de Intervalo de Confian√ßa para uma M√©dia

Voc√™ est√° conduzindo um estudo em para avaliar o impacto de um programa de 
educa√ß√£o financeira na quantidade m√©dia de poupan√ßa mensal dos participantes. 
O objetivo √© determinar se o programa de educa√ß√£o financeira est√° 
ajudando os participantes a poupar dinheiro a cada m√™s.

Para isso, voc√™ coletou uma amostra aleat√≥ria de 30 participantes que 
completaram o programa e registrou a quantidade que cada um deles conseguiu 
poupar em um m√™s (em reais). Com esses dados, voc√™ deseja calcular o intervalo 
de confian√ßa de 95% para a m√©dia da poupan√ßa mensal dos participantes, o 
que fornecer√° uma estimativa da m√©dia de poupan√ßa que pode ser esperada na 
popula√ß√£o geral de participantes do programa. 

Os dados produzidos no estudo foram:

| participante | poupanca_mensal_reais |
|--------------|-----------------------|
| 1            | 150                   |
| 2            | 200                   |
| 3            | 180                   |
| 4            | 220                   |
| 5            | 190                   |
| 6            | 170                   |
| 7            | 210                   |
| 8            | 230                   |
| 9            | 160                   |
| 10           | 200                   |
| 11           | 180                   |
| 12           | 175                   |
| 13           | 190                   |
| 14           | 210                   |
| 15           | 185                   |
| 16           | 165                   |
| 17           | 220                   |
| 18           | 195                   |
| 19           | 205                   |
| 20           | 215                   |
| 21           | 190                   |
| 22           | 200                   |
| 23           | 185                   |
| 24           | 180                   |
| 25           | 210                   |
| 26           | 195                   |
| 27           | 175                   |
| 28           | 170                   |
| 29           | 200                   |
| 30           | 190                   |


- Armazenando os dados em uma data frame:

```{r}
# Carregar os dados simulados
dados_programa <- data.frame(
  participante = 1:30,
  poupanca = c(150, 200, 180, 220, 190, 170, 210, 230, 160, 200,
               180, 175, 190, 210, 185, 165, 220, 195, 205, 215,
               190, 200, 185, 180, 210, 195, 175, 170, 200, 190)
)

dados_programa
```

- A primeira etapa √© verificar se os dados seguem uma distribuic√£o 
aproximadamente normal. Vamos verificar esta hip√≥tese usando um 
gr√°fico quantil-quantil, especificamente, podemos usar a fun√ß√£o 
ggqqplot do pacote ggpubr para produzir o gr√°fico.

```{r}
# pacote utilizado
library(ggpubr)

# Gr√°fico quantil-quantil dos dados
ggqqplot(dados_programa, x = "poupanca") + 
  xlab("quantis te√≥ricos de uma distribui√ß√£o normal padr√£o") + 
  ylab("Quantidade Poupada")
```

O gr√°fico quantil-quantil mostre que √© plaus√≠vel considerar que os dados seguem 
uma distribui√ß√£o aproximadamente normal.

Como as hip√≥teses necess√°rias para a validade de intervalos de 
confian√ßa para uma m√©dia foram verificadas, passamos √† estima√ß√£o 
do intervalo de confian√ßa:

```{r}
# estima o intervalo de confian√ßa de 95% para a m√©dia das medi√ß√µes
resultado <- t.test(dados_programa$poupanca, conf.level = 0.95)
resultado

# exibe apenas a estimativa do IC
resultado <- resultado$conf.int
resultado
```


#### Reportando o resultado

A quantidade m√©dia poupada pelos participantes do programa de 
educa√ß√£o financeira foi R$ 191,50 (IC 95% [184,38 198,62]). 

Como a estimativa por intervalo de confian√ßa para a m√©dia da poupan√ßa mensal 
n√£o cont√©m zero podemos concluir, com 95% de confian√ßa, que os dados da 
pesquisa fornecem evid√™ncia de que a participa√ß√£o no programa de educa√ß√£o financeira tem um impacto positivo na quantidade poupada mensalmente, sendo 
que a quantidade m√©dia poupada pelos participantes varia entre 
R\$ 184,38 e R\$ 198,62 por m√™s.
:::
::::




## Aplica√ß√£o 4

:::: {style="font-size: 90%;"}

::: {.callout-note icon=false}
## Estima√ß√£o de Intervalo de Confian√ßa para Comparar Duas M√©dias

Voc√™ est√° conduzindo um experimento em Economia Comportamental para avaliar o 
impacto de dois diferentes tipos de incentivo (monet√°rio vs. n√£o monet√°rio) 
na produtividade dos funcion√°rios medida como unidades produzidas por 
semana. 

Voc√™ coletou uma amostra aleat√≥ria de funcion√°rios e os dividiu em 
dois grupos:

- Grupo A (Incentivo Monet√°rio)
- Grupo B (Incentivo N√£o Monet√°rio)

Voc√™ mediu a produtividade dos funcion√°rios (em unidades de produ√ß√£o por 
semana) ap√≥s a implementa√ß√£o dos incentivos. Os dados produzidos pelo 
experimento foram: 

| grupo | produtividade |
|-------|---------------|
| A     | 50            |
| A     | 55            |
| A     | 53            |
| A     | 58            |
| A     | 52            |
| A     | 56            |
| A     | 54            |
| A     | 57            |
| A     | 51            |
| A     | 55            |
| A     | 59            |
| A     | 52            |
| A     | 53            |
| A     | 56            |
| A     | 57            |
| A     | 54            |
| A     | 52            |
| A     | 50            |
| A     | 53            |
| A     | 56            |
| B     | 48            |
| B     | 45            |
| B     | 47            |
| B     | 49            |
| B     | 46            |
| B     | 44            |
| B     | 48            |
| B     | 47            |
| B     | 45            |
| B     | 46            |
| B     | 49            |
| B     | 44            |
| B     | 45            |
| B     | 48            |
| B     | 47            |
| B     | 46            |
| B     | 44            |
| B     | 45            |
| B     | 46            |
| B     | 47            |

- Qual tipo de incentivo apresentou o maior impacto na produtividade dos 
funcion√°rios?

- Armazenando os dados em uma data frame:

```{r}
# cria data frame para armazenar os dados
dados_incentivos <- data.frame(
  grupo = c(rep("A", 20), rep("B", 20)),
  produtividade = c(50, 55, 53, 58, 52, 56, 54, 57, 51, 55,
                    59, 52, 53, 56, 57, 54, 52, 50, 53, 56,
                    48, 45, 47, 49, 46, 44, 48, 47, 45, 46,
                    49, 44, 45, 48, 47, 46, 44, 45, 46, 47)
)
```

- Novamente, vamos verificar se os dados, referentes aos dois 
grupos do estudo, seguem uma distribui√ß√£o aproximadamente normal utilizando 
gr√°ficos quantil-quantil:

```{r}
# pacote utilizado
library(ggpubr)

# Gr√°fico quantil-quantil dos dados
ggqqplot(dados_incentivos, x = "produtividade", 
         color = "grupo", 
         palette = c("#00AFBB", "#E7B800")) 
```

V√™-se que os dados de ambos os grupos est√£o dentro do intervalo de 
confian√ßa, assim, √© plaus√≠vel considerar que os dados de ambos os 
grupos seguem uma distribui√ß√£o aproximadamente normal.

A estima√ß√£o de um intervalo de confian√ßa para a diferen√ßa entre as m√©dias dos
dois grupos √© obtida com:

```{r}
# Realizar o teste t para calcular o intervalo de confian√ßa
resultado <- t.test(produtividade ~ grupo, 
                    data = dados_incentivos, 
                    conf.level = 0.95, 
                    var.equal = FALSE)
resultado

# exibe apenas a estimativa do IC
resultado$conf.int
```

#### Reportando o Resultado 

A estimativa do intervalo com 95% de confian√ßa, com corre√ß√£o de Welch, para 
a diferen√ßa entre as produtividades m√©dias do grupo que recebeu incentivo 
monet√°rio (M = 54,15 unidades produzidas) e o grupo qque recebeu 
incentivo n√£o monet√°rio (M = 46,30 unidades produzidas), 
sugere que a diferen√ßa √© positiva e estatisticamente significativa 
(diferen√ßa = 7,85, IC 95% [6,46, 9,24], t(31,49) = 11,51).
:::
::::




## Tipos de Erro em Pesquisas 

:::: {style="font-size: 90%;"}

::: {.callout-important icon=false}
## Erros Relacionados √† Amostragem

**Erro de Amostragem** (coberto pela margem de erro):  

- Varia√ß√£o natural dos resultados ao se usar uma amostra ao inv√©s de um censo. 
Esse erro √© control√°vel por m√©todos estat√≠sticos, sendo o **√∫nico** refletido 
na margem de erro.

**Erro de Cobertura**:  

- Ocorre quando parte da popula√ß√£o-alvo tem 
**probabilidade nula ou desigual de sele√ß√£o**, comprometendo a 
representatividade da amostra.  *Exemplo*: exclus√£o de pessoas sem 
celular em pesquisas por telefone.

**Erro de N√£o-Resposta**:  

- Quando h√° 
**diferen√ßas sistem√°ticas entre quem responde e quem n√£o responde**, 
introduzindo vi√©s nos resultados. 

**Implica√ß√£o**: Mesmo com amostragem aleat√≥ria, esses erros podem comprometer 
a validade da infer√™ncia. Devem ser documentados e comunicados sempre 
que presentes.
:::
::::  




## Tipos de Erro em Pesquisas 

:::: {style="font-size: 90%;"}

::: {.callout-important icon=false}
## Erros na Medi√ß√£o e An√°lise

**Erro de Medi√ß√£o**:  

- *Instrumento*: Perguntas amb√≠guas, enviesadas ou mal formuladas, 
ou ainda influ√™ncia do entrevistador.  
- *Declara√ß√£o*: Respostas falsas, por press√£o social ou desejo de agradar.

**Erro Temporal**:  

- Mudan√ßas reais na opini√£o p√∫blica entre a coleta dos dados e o evento 
de interesse (ex: elei√ß√£o, lan√ßamento de produto).

**Erro de Processamento**: 

- Erros cometidos na entrada, codifica√ß√£o ou an√°lise dos dados.

**Implica√ß√£o**:  

- Esses erros **n√£o s√£o refletidos na margem de erro estat√≠stica**, mas podem 
introduzir vieses significativos.  

- A comunica√ß√£o respons√°vel deve explicitar que a margem de erro 
cobre **apenas a variabilidade amostral aleat√≥ria**.
:::
::::



## Refer√™ncias

::: {#refs}
:::



## Atualizando os Reposit√≥rios

:::: {style="font-size: 85%;"}

::: {.callout-tip}
## Instru√ß√µes

1. No terminal do RStudio, verifique quais arquivos/pastas foram
modificados ou criados com:

```{.bash style="font-size: 1.1em;"}
git status
```

2. Voc√™ pode adicionar todos os arquivos de uma vez com:

```{.bash style="font-size: 1.1em;"}
git add .
```

3. Execute git status novamente para confirmar que todos os arquivos foram adicionados (aparecer√£o em <span style="color: green;">verde</span> sob "*Changes to be committed*"):

```{.bash style="font-size: 1.1em;"}
git status
```

4. Se tudo estiver em <span style="color: green;">verde</span>, fa√ßa um commit com uma mensagem descritiva:

```{.bash style="font-size: 1.1em;"}
git commit -m "atualizacoes aula 13"
```

5. Se algum arquivo ou pasta ainda aparecer em <span style="color: red;">vermelho</span> ap√≥s o 
segundo git status, adicione as pastas/arquivos um por um:

```{.bash style="font-size: 1.2em;"}
git add relatorios/09-relatorio/10-relatorio.qmd
```

6. Execute git status novamente e fa√ßa o commit quando todos os arquivos
estiverem em verde:

```{.bash style="font-size: 1.1em;"}
git commit -m "atualizacoes aula 13"
```

7. Envie o reposit√≥rio local atualizado para o GitHub:

```{.bash style="font-size: 1.1em;"}
git push origin main
```
:::
::::



